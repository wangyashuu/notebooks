{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceType": "competition",
          "sourceId": 39585,
          "databundleVersionId": 4786639
        },
        {
          "sourceType": "datasetVersion",
          "sourceId": 5076707,
          "datasetId": 2939693,
          "databundleVersionId": 5147503
        },
        {
          "sourceType": "datasetVersion",
          "sourceId": 4857804,
          "datasetId": 2787243,
          "databundleVersionId": 4924543
        }
      ],
      "dockerImageVersionId": 30396,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "ZgZG33XUrOjb",
        "1AiNlGL_rwn_",
        "UIhHnDhJ0a2o",
        "MGunJE1BTgEK"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wangyashuu/notebooks/blob/main/Tutorial_04_(huggingface)_Learning_Equality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "https://www.kaggle.com/competitions/learning-equality-curriculum-recommendations\n",
        "\n",
        "*"
      ],
      "metadata": {
        "id": "46P0CjrPrE3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download"
      ],
      "metadata": {
        "id": "ZgZG33XUrOjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install \\\n",
        "#     --extra-index-url=https://pypi.nvidia.com \\\n",
        "#     cudf-cu12==24.4.* dask-cudf-cu12==24.4.* cuml-cu12==24.4.* \\\n",
        "#     cugraph-cu12==24.4.* cuspatial-cu12==24.4.* cuproj-cu12==24.4.* \\\n",
        "#     cuxfilter-cu12==24.4.* cucim-cu12==24.4.* pylibraft-cu12==24.4.* \\\n",
        "#     raft-dask-cu12==24.4.* cuvs-cu12==24.4.*\n",
        "\n",
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpTbWjfxWCJi",
        "outputId": "6da14f59-dcf4-49ac-f324-be3d9ec2d070"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.30.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.5.40)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'learning-equality-curriculum-recommendations:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F39585%2F4786639%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240528%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240528T163732Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D095763b91bd541bab3fc45a1a54066dbb9a4fa717b4eeaaf48364f6b70fb74bb0b18d9b89de4ef400080b32a6506b7ad55a49809a06b5ccc2907ce9afe5b1d3b67fe4bf915e936eb465f4f2c58fd00d7a22a989217cce05ce00dea6cdbb388f5d77775feab15fe991e9a68e35744dc098cccf4c3c1d3d9b44c40bcc51c770ce8a8a6c727f72d1133b743715ba7f21fe1ec306660043d7269678b9fe406004108643c96d6d3951495b1572f8459e65196da45f0afc2c35d741ace2896cefd6443d0de3722e5c182edd525790ffe2d9da01b2f184f3c12ef90341e87d0c4d27a8048b67e482c917f3fc35d1027aec67427123b8dda8b7bd0df7d45d65bc3cc378c,lecr0297train:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2787243%2F4857804%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240528%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240528T163732Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4da855f949828e23170f326c842e9785a51a154a45ef84bec851f3a2edc26c47bf7495e3d865cff1a7b61a1af30352f29a7a7d416f794c0e791f4be22b9f6607d495484e9669e5eee94e446bc92c96adb71aa001c0d58ff94ad4646cc3ba74a0e00b36b7671517ba71f2d9b8f03edf85ca1c0fba610951d5b110f2792ec92b020ceb1619cd7fd91a421a14a94afa6a19cd0d66c86d133a9f039b6ac53c16a9a1eccaaf7519e4d1e5215212c20db558187d9f0ba103e4df796e29f55b10557c16b52411bc8e18e0454d79826b85b88eca280835ddc96f3799eb51f8e711563b8d8a94eb73f126dca3c79f528052328b1d28607c4d5a7e66ff420d415be01f1955,learning-equality:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2939693%2F5076707%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240528%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240528T163732Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D77e4ce9fa92283aae06ec808ab07d5b5e46570050056396ba93bf4dff61ab05ddb5539f8ee062643d52f05b3fd795747f214056273cb6c32be09e6ded32157220b0997443d67ba5a1253abab497e8f2bdde156a86f65d24aee5056cabfa80db14aac47c6a7eaa01d55be79cdc24c2111993bf9292bebb5194a7de3c10930e2d80b99e881e4e05c3e26d61c8e9e7a73a42cbfdd7d914c76d4268f0d6c5e1023fb96d3e42959ee74aa4f57922af7fba3bbc0d8239b09c3a0698eb1cd57a31152ffce8745729e4ed6101096f4436e692b811f05a4b71cf0d311053ad028341b294b308d3b93660378e433ecc1c02ae68ddde1f87fbfd801cc06c1800f93f4dad307'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "dsFQgUTaB9YL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10f22d37-0ad2-4ae9-8162-b78aed2bdeef"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading learning-equality-curriculum-recommendations, 266113590 bytes compressed\n",
            "[==================================================] 266113590 bytes downloaded\n",
            "Downloaded and uncompressed: learning-equality-curriculum-recommendations\n",
            "Downloading lecr0297train, 1790030265 bytes compressed\n",
            "[==================================================] 1790030265 bytes downloaded"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare"
      ],
      "metadata": {
        "id": "1AiNlGL_rwn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# import evaluate\n",
        "# import cupy as cp\n",
        "# from cuml.metrics import pairwise_distances\n",
        "# from cuml.neighbors import NearestNeighbors\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder, RobustScaler\n",
        "# import seaborn as sns"
      ],
      "metadata": {
        "id": "fRLase8udOu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DMNMZ0D1dOKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = KAGGLE_INPUT_PATH + '/learning-equality-curriculum-recommendations/'\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class Config:\n",
        "    seed = 2024\n",
        "    k_fold = 5\n",
        "    n_epochs = 10"
      ],
      "metadata": {
        "id": "xbO4UBk-vHqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_content = pd.read_csv(data_path + \"content.csv\")\n",
        "df_correlations = pd.read_csv(data_path + \"correlations.csv\")\n",
        "df_topics = pd.read_csv(data_path + \"topics.csv\")\n",
        "\n",
        "df_content.shape, df_correlations.shape, df_topics.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-06T16:03:03.286743Z",
          "iopub.execute_input": "2024-03-06T16:03:03.28707Z",
          "iopub.status.idle": "2024-03-06T16:03:12.942606Z",
          "shell.execute_reply.started": "2024-03-06T16:03:03.287044Z",
          "shell.execute_reply": "2024-03-06T16:03:12.939593Z"
        },
        "trusted": true,
        "id": "6sPaS6zGB9YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_content.head()"
      ],
      "metadata": {
        "id": "Lc_9mxRU3btw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_correlations.head()"
      ],
      "metadata": {
        "id": "KAmUZgIV310X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_topics.head()"
      ],
      "metadata": {
        "id": "5xLtd4j534VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration"
      ],
      "metadata": {
        "id": "UIhHnDhJ0a2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Missing Values"
      ],
      "metadata": {
        "id": "VeoArIyj0gax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def na_status(df, params = dict()):\n",
        "    na_counts = pd.isna(df).sum()\n",
        "    n = len(df.index)\n",
        "    df_status = pd.DataFrame(\n",
        "        dict(na_counts=na_counts, na_percents=na_counts / n, **params),\n",
        "        index=df.columns\n",
        "    )\n",
        "\n",
        "    df_status[df_status['na_counts'] > 0].sort_values('na_counts', ascending=False)\n",
        "    return df_status"
      ],
      "metadata": {
        "id": "ZQQRk_US4QzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "na_status(df_content)"
      ],
      "metadata": {
        "id": "DRoksb9T4mkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "na_status(df_correlations)"
      ],
      "metadata": {
        "id": "8UxfoCFuG0OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "na_status(df_topics)"
      ],
      "metadata": {
        "id": "kgZzMcwt5AGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mislabeled Values"
      ],
      "metadata": {
        "id": "yUCqH8boHAHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_content.describe()"
      ],
      "metadata": {
        "id": "v79JPe8LG7_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_correlations.describe()"
      ],
      "metadata": {
        "id": "MuJU_Csl50sV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_topics.describe()"
      ],
      "metadata": {
        "id": "ocd6-nhaHl5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(df_content.groupby(['title']).nunique() > 1).sum()"
      ],
      "metadata": {
        "id": "i_e-gzMxHq_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling"
      ],
      "metadata": {
        "id": "-MWVJyEsT2cO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model and Dataset"
      ],
      "metadata": {
        "id": "MGunJE1BTgEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm_name = 'dbmdz/bert-tiny-historic-multilingual-cased'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(lm_name)"
      ],
      "metadata": {
        "id": "RBy9Jr8Pqtos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WrapperModel(torch.nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, **inputs):\n",
        "        model = self.model\n",
        "        anchor, positive, negative = inputs['anchor'], inputs['positive'], inputs['negative']\n",
        "        anchor_output = model(**anchor)\n",
        "        positive_output = model(**positive)\n",
        "        negative_output = model(**negative)\n",
        "\n",
        "        return (anchor_output.last_hidden_state.mean(dim=1),\n",
        "            positive_output.last_hidden_state.mean(dim=1),\n",
        "            negative_output.last_hidden_state.mean(dim=1))\n",
        "\n",
        "\n",
        "triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2, eps=1e-7)\n",
        "\n",
        "\n",
        "class TripletTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        outputs = model(**inputs)\n",
        "        anchor, positive, negative = outputs\n",
        "        loss = triplet_loss(anchor, positive, negative)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "\n",
        "def accuracy_triplet(anchor, positive, negative, margin = 0):\n",
        "    positive_distance = torch.dist(anchor, positive, p=2)\n",
        "    negative_distance = torch.dist(anchor, negative, p=2)\n",
        "    pred = (negative_distance - positive_distance - margin) > 0\n",
        "    return pred.sum() / len(anchor)"
      ],
      "metadata": {
        "id": "Z9CQBcmu4wyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_fields(df, fields, padding=True, truncation=True, return_tensors=\"pt\"):\n",
        "    text = ''\n",
        "    for f in fields:\n",
        "        text += df[f]\n",
        "\n",
        "    return tokenizer(\n",
        "        text.fillna('').to_list(),\n",
        "        padding=padding,\n",
        "        truncation=truncation,\n",
        "        return_tensors=return_tensors)\n",
        "\n",
        "\n",
        "def rand_not_in(arr, excludes):\n",
        "    while True:\n",
        "        idx = np.random.randint(len(arr))\n",
        "        if arr[idx] not in excludes:\n",
        "            return idx\n",
        "\n",
        "\n",
        "class CorrelationDataset(Dataset):\n",
        "    def __init__(self, df_correlations, df_topics, df_content, tokenizer):\n",
        "        ids_topic = df_correlations['topic_id']\n",
        "        token_topics = tokenize_fields(\n",
        "            df_topics.set_index('id').loc[ids_topic],\n",
        "             ['title', 'description'])\n",
        "        ids_content = list(set(df_correlations['content_ids'].str.cat(sep=' ').split()))\n",
        "        token_content = tokenize_fields(\n",
        "            df_content.set_index('id').loc[ids_content],\n",
        "             ['title', 'description'])\n",
        "        self.df_correlations = df_correlations\n",
        "        self.ids_topics = pd.Index(ids_topic)\n",
        "        self.token_topics = token_topics\n",
        "        self.ids_content = pd.Index(ids_content)\n",
        "        self.token_content = token_content\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_correlations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tid, cids = self.df_correlations.iloc[idx]\n",
        "        cids = cids.split()\n",
        "        a_idx = self.ids_topics.get_loc(tid)\n",
        "        p_idx = self.ids_content.get_loc(cids[np.random.randint(len(cids))])\n",
        "        n_idx = rand_not_in(self.ids_content, cids)\n",
        "        anchor = {k: v[a_idx] for k, v in self.token_topics.items()}\n",
        "        positive = {k: v[p_idx] for k, v in self.token_content.items()}\n",
        "        negative = {k: v[n_idx] for k, v in self.token_content.items()}\n",
        "        return dict(anchor=anchor, positive=positive, negative=negative)\n"
      ],
      "metadata": {
        "id": "70IP8_wqnaXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "dml3-ToWTYdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=Config.k_fold, random_state=Config.seed, shuffle=True)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    outputs, labels = eval_pred\n",
        "    return dict(accuracy=accuracy_triplet(*outputs))\n",
        "\n",
        "limit_size = 10000\n",
        "df_filtered = df_correlations[:limit_size]\n",
        "\n",
        "models = []\n",
        "for i, (train_index, test_index) in enumerate(kf.split(df_filtered)):\n",
        "    params = dict(df_topics=df_topics, df_content=df_content, tokenizer=tokenizer)\n",
        "    dataset_train = CorrelationDataset(df_filtered.iloc[train_index], **params)\n",
        "    dataset_test = CorrelationDataset(df_filtered.iloc[test_index], **params)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir= KAGGLE_WORKING_PATH + '/' + str(i),\n",
        "        num_train_epochs=1, # Config.n_epochs,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        remove_unused_columns=False,\n",
        "        logging_steps=20,\n",
        "        learning_rate=1e-4)\n",
        "\n",
        "    model = AutoModel.from_pretrained(lm_name)\n",
        "    wrapper_model = WrapperModel(model)\n",
        "    trainer = TripletTrainer(\n",
        "        model=wrapper_model,\n",
        "        args=training_args,\n",
        "        train_dataset=dataset_train,\n",
        "        eval_dataset=dataset_test,\n",
        "        data_collator=default_collate,\n",
        "        compute_metrics=compute_metrics)\n",
        "    trainer.train()\n",
        "    models.append(model)\n",
        "    break"
      ],
      "metadata": {
        "id": "uQsPc2hBB9YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rZt96pQuy_sI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "https://docs.rapids.ai/api/cuml/stable/api/#neighbors\n",
        "https://github.com/rapidsai/cuml/blob/main/notebooks/nearest_neighbors_demo.ipynb"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-06T15:47:02.389485Z",
          "iopub.execute_input": "2024-03-06T15:47:02.389947Z",
          "iopub.status.idle": "2024-03-06T15:47:03.342656Z",
          "shell.execute_reply.started": "2024-03-06T15:47:02.389909Z",
          "shell.execute_reply": "2024-03-06T15:47:03.341646Z"
        },
        "trusted": true,
        "id": "kkiRBwE7B9YW",
        "outputId": "01cc955d-f0ab-421b-cfc0-b0c08dfb3f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\ncontent.csv  correlations.csv  sample_submission.csv  topics.csv\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def distance_by_ids(ids):\n",
        "    topic_idx = topics.loc[topics['id'] == ids[0]].index.item()\n",
        "    content_idx = content.loc[content['id'] == ids[1]].index.item()\n",
        "\n",
        "    return 1 - F.cosine_similarity(\n",
        "        torch.tensor(topic_embeddings[[topic_idx]]),\n",
        "        torch.tensor(content_embeddings[[content_idx]])\n",
        "    )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-20T17:32:59.457096Z",
          "iopub.execute_input": "2023-02-20T17:32:59.457476Z",
          "iopub.status.idle": "2023-02-20T17:32:59.464249Z",
          "shell.execute_reply.started": "2023-02-20T17:32:59.457437Z",
          "shell.execute_reply": "2023-02-20T17:32:59.463094Z"
        },
        "trusted": true,
        "id": "WEnkMl_yB9Ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Useful Links\n",
        "\n",
        "* what did in feature extraction pipeline https://huggingface.co/tasks/feature-extraction\n",
        "\n",
        "* [Tips and Recommendations from Hosts](https://www.kaggle.com/code/jamiealexandre/tips-and-recommendations-from-hosts/notebook)"
      ],
      "metadata": {
        "id": "bmzsk5C7B9Yi"
      }
    }
  ]
}